//
//  Agents.swift
//  
//
//  Created by Niklas Holmgren on 2023-03-02.
//

import Foundation

public typealias StepCallback<E: Environment, State> =
    (inout E, inout Trajectory<E.Observation, State, E.Action, E.Reward>) -> Void

public protocol Agent {
    associatedtype Environment: ReinforcementLearning.Environment
    associatedtype State
    
    var actionSpace: Environment.ActionSpace { get }
    var state: State { get set }
    
    mutating func action(for step: Step<Observation, Reward>) async throws -> Action

    @discardableResult
    mutating func update(
        using trajectory: Trajectory<Observation, State, Action, Reward>
    ) async throws -> Float

    @discardableResult
    mutating func update(
      using environment: inout Environment,
      maxSteps: Int,
      maxEpisodes: Int,
      callbacks: [StepCallback<Environment, State>]
    ) async throws -> Float
}

extension Agent {
    public typealias Observation = Environment.Observation
    public typealias Action = Environment.Action
    public typealias Reward = Environment.Reward
    
    @inlinable
    public mutating func run(
        in environment: inout Environment,
        maxSteps: Int = Int.max,
        maxEpisodes: Int = Int.max,
        callbacks: [StepCallback<Environment, State>] = []
    ) async throws {
        var currentStep = environment.currentStep
        var numSteps = 0
        var numEpisodes = 0
        while numSteps < maxSteps && numEpisodes < maxEpisodes {
            let state = self.state
            let action = try await self.action(for: currentStep)
            let nextStep = try environment.step(taking: action)
            var trajectory = Trajectory(
                stepKind: nextStep.kind,
                observation: currentStep.observation,
                state: state,
                action: action,
                reward: nextStep.reward)
            callbacks.forEach { $0(&environment, &trajectory) }
            numSteps += 1
            numEpisodes += nextStep.kind == .last ? 1 : 0
            currentStep = nextStep
        }
    }
}

/// Trajectory generated by having an agent interact with an environment.
///
/// Trajectories consist of five main components. The five components are:
///   - `stepKind`: Represents the kind of each time step (i.e., "first", "transition", or "last").
///     For example, if the agent takes an action in time step `t` that results in the current
///     episode ending, then `stepKind[t]` will be "last" and `stepKind[t + 1]` will be "first".
///   - `observation`: Observation that the agent receives from the environment in the beginning
///     of each time step.
///   - `state`: State of the agent at the beginning of each time step.
///   - `action`: Action the agent took in each time step.
///   - `reward`: Reward that the agent received from the environment after each action. The reward
///     received after taking `action[t]` is `reward[t]`.
public struct Trajectory<Observation, State, Action, Reward> {
    public var steps: [Step]
    
    public struct Step {
        public var stepKind: StepKind
        public var observation: Observation
        public var state: State
        public var action: Action
        public var reward: Reward
    }
    
    public var currentStep: Step? {
        steps.last
    }
    
    public init() {
        self.steps = []
        self.numSteps = 0
        self.numEpisodes = 0
    }
    
    public init(
        stepKind: StepKind,
        observation: Observation,
        state: State,
        action: Action,
        reward: Reward
    ) {
        self.steps = [
            Step(
                stepKind: stepKind,
                observation: observation,
                state: state,
                action: action,
                reward: reward
            )
        ]
        self.numSteps = 1
        self.numEpisodes = stepKind == .last ? 1 : 0
    }
    
    @discardableResult
    public mutating func append(
        stepKind: StepKind,
        observation: Observation,
        state: State,
        action: Action,
        reward: Reward
    ) -> Self {
        let step = Step(
            stepKind: stepKind,
            observation: observation,
            state: state,
            action: action,
            reward: reward
        )
        self.steps.append(step)
        self.numSteps += 1
        self.numEpisodes += stepKind == .last ? 1 : 0
        return self
    }
    
    public var numSteps: Int
    public var numEpisodes: Int
}

public struct AgentInput<Observation, State> {
  public let observation: Observation
  public var state: State

  @inlinable
  public init(observation: Observation, state: State) {
    self.observation = observation
    self.state = state
  }
}
